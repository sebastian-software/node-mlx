# Porting Decisions: mlx-lm (Python) â†’ NodeMLXCore (Swift)

This document tracks architectural decisions made during the port from Apple's `mlx-lm` Python library to Swift.

## Source of Truth

**Decision**: Port directly from `mlx-lm` (Python), not from `mlx-swift-lm` (Swift).

**Why**:

- `mlx-lm` is updated more frequently and supports more models
- `mlx-swift-lm` lags behind in features and model support
- Direct Pythonâ†’Swift porting gives us full control

**Reference**: https://github.com/ml-explore/mlx-lm/tree/main/mlx_lm/models

**Current Version**:

- Git Hash: `7585c142a6be9c9245f4ce61d087839776cb8275`
- Ported: 2026-01-12

---

## Architecture Overview

```
Sources/NodeMLXCore/
â”œâ”€â”€ generated/          # Auto-generated by hf2swift (DO NOT EDIT)
â”‚   â””â”€â”€ models/         # Per-model Swift implementations
â”œâ”€â”€ ported/             # LLM-ported from mlx-lm Python
â”‚   â”œâ”€â”€ KVCache.swift
â”‚   â”œâ”€â”€ RoPEUtils.swift
â”‚   â”œâ”€â”€ SwitchLayers.swift
â”‚   â””â”€â”€ GemmaRMSNorm.swift
â”œâ”€â”€ shared/             # Hand-written reusable components
â”‚   â”œâ”€â”€ Protocols.swift
â”‚   â”œâ”€â”€ StandardAttention.swift
â”‚   â”œâ”€â”€ StandardMLP.swift
â”‚   â”œâ”€â”€ AltUpBlock.swift
â”‚   â””â”€â”€ ...
â””â”€â”€ (root)              # Hand-written integration code
    â”œâ”€â”€ Generate.swift
    â”œâ”€â”€ LLMModel.swift
    â”œâ”€â”€ NodeMLXCore.swift
    â””â”€â”€ Tokenizer.swift
```

### Three-Layer Design

| Layer          | Source               | Editing              | Purpose                      |
| -------------- | -------------------- | -------------------- | ---------------------------- |
| **generated/** | `hf2swift` generator | âŒ Never             | Model-specific code          |
| **ported/**    | `mlx-lm` Python      | ğŸ”„ Re-port to update | Core MLX infrastructure      |
| **shared/**    | Hand-written         | âœ… Free to edit      | Shared components, protocols |
| **root**       | Hand-written         | âœ… Free to edit      | Node.js integration          |

---

## Shared Components (shared/)

Reusable Swift components that reduce generated code by ~70%.

### Protocols

| Protocol                     | Purpose                                               |
| ---------------------------- | ----------------------------------------------------- |
| `BaseModelConfiguration`     | Common config properties (hiddenSize, numHeads, etc.) |
| `AttentionConfiguration`     | Extends base with attention scale                     |
| `SlidingWindowConfiguration` | Sliding window support                                |
| `MoEConfiguration`           | Mixture of Experts support                            |
| `AltUpConfiguration`         | Alternating Updates (Gemma3n)                         |
| `LaurelConfiguration`        | Low-rank residual (Gemma3n)                           |

### Standard Components

| Component                 | Used By      | Description                |
| ------------------------- | ------------ | -------------------------- |
| `StandardAttention<C>`    | Llama, Qwen2 | GQA attention with RoPE    |
| `StandardMLP<C>`          | Llama, Qwen2 | SwiGLU MLP block           |
| `StandardDecoderLayer<C>` | Llama, Qwen2 | Pre-norm decoder           |
| `FusedQKVAttention<C>`    | Phi3, Phi4   | Fused QKV projection       |
| `RMSNorm`                 | Most models  | Standard RMS normalization |

### Specialized Components

| Component        | Used By | Description                        |
| ---------------- | ------- | ---------------------------------- |
| `AltUpBlock<C>`  | Gemma3n | Alternating Updates sparse compute |
| `LaurelBlock<C>` | Gemma3n | Low-rank residual layer            |
| `SparseMLP<C>`   | Gemma3n | gelu_topk sparse activation        |
| `MoESanitizer`   | GPT-OSS | MoE weight transformation          |
| `MathUtils`      | Various | erfinv, clipResidual, topK         |

---

## Ported Components (ported/)

### KVCache (cache.py â†’ KVCache.swift)

| Python Class              | Swift Class             | Notes                   |
| ------------------------- | ----------------------- | ----------------------- |
| `KVCache`                 | `StandardKVCache`       | Grow-in-place, step=256 |
| `RotatingKVCache`         | `RotatingKVCache`       | Sliding window + sinks  |
| `QuantizedKVCache`        | `QuantizedKVCache`      | 8-bit quantized         |
| `create_causal_mask()`    | `createCausalMask()`    | Window support          |
| `create_attention_mask()` | `createAttentionMask()` | MLXFast mask mode       |

**Not Ported**: BatchKVCache, MambaCache, ChunkedKVCache, CacheList (niche use cases)

### RoPE Utils (rope_utils.py â†’ RoPEUtils.swift)

| Python              | Swift              | Notes                          |
| ------------------- | ------------------ | ------------------------------ |
| `nn.RoPE`           | `StandardRoPE`     | RoPEProvider wrapper           |
| `Llama3RoPE`        | `Llama3RoPE`       | Smooth frequency interpolation |
| `YarnRoPE`          | `YarnRoPE`         | Beta-based correction          |
| `SuScaledRoPE`      | `SuScaledRoPE`     | Long context (longrope)        |
| `initialize_rope()` | `initializeRope()` | Factory function               |

**Supported rope_type**: default, linear, llama3, yarn, longrope, mrope

### SwitchLayers (switch_layers.py â†’ SwitchLayers.swift)

| Python                  | Swift                   | Notes                      |
| ----------------------- | ----------------------- | -------------------------- |
| `_gather_sort()`        | `gatherSort()`          | Token sorting for batching |
| `_scatter_unsort()`     | `scatterUnsort()`       | Restore order              |
| `SwitchLinear`          | `SwitchLinear`          | Expert-specific linear     |
| `QuantizedSwitchLinear` | `QuantizedSwitchLinear` | Quantized variant          |
| `SwitchGLU`             | `SwitchGLU`             | Gated linear + experts     |
| `swiglu()`              | `swiGLU()`              | Activation function        |

**GPT-OSS Specific**: `gptOssSwiGLU()` with limit=7.0 clipping

### GemmaRMSNorm (gemma.py â†’ GemmaRMSNorm.swift)

| Python    | Swift          | Notes                |
| --------- | -------------- | -------------------- |
| `RMSNorm` | `GemmaRMSNorm` | (1 + weight) scaling |

---

## Generator Architecture (hf2swift)

The `hf2swift` generator creates Swift model code from HuggingFace patterns.

### Model Definitions

```
packages/hf2swift/src/generator/
â”œâ”€â”€ model-defs/           # One file per model family
â”‚   â”œâ”€â”€ types.ts          # Interfaces + defaults
â”‚   â”œâ”€â”€ llama.ts          # Llama family
â”‚   â”œâ”€â”€ qwen.ts           # Qwen2, Qwen3
â”‚   â”œâ”€â”€ gemma.ts          # Gemma3, Gemma3n
â”‚   â”œâ”€â”€ phi.ts            # Phi3, Phi4
â”‚   â”œâ”€â”€ mistral.ts        # Mistral, Mistral3
â”‚   â”œâ”€â”€ gpt-oss.ts        # GPT-OSS MoE
â”‚   â””â”€â”€ smollm.ts         # SmolLM3
â””â”€â”€ components/           # Swift code generators
    â”œâ”€â”€ attention.ts
    â”œâ”€â”€ mlp.ts
    â”œâ”€â”€ decoder-layer.ts
    â””â”€â”€ model.ts
```

### Feature-Based Routing

The generator uses **feature flags**, not model names, to decide what code to generate:

```typescript
// Simple models â†’ use shared components
if (canUseSharedStandardAttention(features)) {
  return `typealias ${model}Attention = StandardAttention<${config}>`
}

// Complex models â†’ generate custom code
return generateCustomAttention(model, features)
```

### Generated Output

For simple models (Llama, Qwen2):

```swift
// MARK: - Attention
typealias LlamaAttention = StandardAttention<LlamaConfiguration>

// MARK: - MLP
typealias LlamaMLP = StandardMLP<LlamaConfiguration>

// MARK: - Decoder Layer
typealias LlamaDecoderLayer = StandardDecoderLayer<LlamaConfiguration>
```

For complex models (Gemma3n, GPT-OSS): Full custom implementation.

---

## Design Principles

1. **Focus on popular models**: Llama, Qwen, Phi, Gemma, Mistral, GPT-OSS
2. **Skip niche features**: Batch processing, SSM models, prompt caching
3. **Premium Swift quality**: Protocols, documentation, type safety
4. **Testable components**: Shared code is tested once, used everywhere
5. **Clean separation**: Generated vs. ported vs. hand-written
6. **Feature-driven generation**: Not model-name-driven

---

## Updating Components

### To update ported code

1. Check latest mlx-lm commit
2. Download Python source
3. Use `/port-python-to-swift` command in Cursor
4. Update git hash in file header
5. Run tests

### To add a new model

1. Create `model-defs/<model>.ts` with features and defaults
2. Register in `model-defs/index.ts`
3. Regenerate: `pnpm hf2swift --model <name> --output ...`
4. Run Swift build and tests

---

## Version History

| Date       | mlx-lm Hash   | Changes                                   |
| ---------- | ------------- | ----------------------------------------- |
| 2026-01-12 | `7585c142...` | Initial port: KVCache, RoPE, SwitchLayers |
